{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Data with tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/woongjae/Desktop/gradu/project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import yaml\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_load1.ipynb    graduation.py          train_v1.ipynb\n",
      "dataset_load2.ipynb    \u001b[34mgraduation_projuct_ML\u001b[m\u001b[m/ train_v2.ipynb\n",
      "\u001b[34mdataset_v1\u001b[m\u001b[m/            \u001b[34msample_data\u001b[m\u001b[m/           \u001b[34multralytics\u001b[m\u001b[m/\n",
      "\u001b[34mdataset_v2\u001b[m\u001b[m/            tensorflow_v1.py\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/woongjae/Desktop/gradu/project/dataset_v2\n"
     ]
    }
   ],
   "source": [
    "cd dataset_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.dataset.txt   data.yaml            \u001b[34mtrain\u001b[m\u001b[m/\n",
      "README.roboflow.txt  \u001b[34mtest\u001b[m\u001b[m/                \u001b[34mvalid\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: ../train/images\n",
      "val: ../valid/images\n",
      "test: ../test/images\n",
      "\n",
      "nc: 22\n",
      "names: ['Hoodie', 'Jacket', 'Mid-lenght dress', 'Pants', 'Shirt', 'coat', 'dress', 'fabric', 'jacket', 'jean', 'm2m', 'plain', 'shirt', 'short', 'shorts', 'skirt', 'slacks', 'suit', 'sweat', 'tie', 'tracksuit', 'tshirt']\n",
      "\n",
      "roboflow:\n",
      "  workspace: huseyin-ahrh5\n",
      "  project: 01234\n",
      "  version: 5\n",
      "  license: CC BY 4.0\n",
      "  url: https://universe.roboflow.com/huseyin-ahrh5/01234/dataset/5"
     ]
    }
   ],
   "source": [
    "cat data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = glob(\"/Users/woongjae/Desktop/gradu/project/dataset_v2/train/images/*.jpg\")\n",
    "valid_list = glob(\"/Users/woongjae/Desktop/gradu/project/dataset_v2/valid/images/*.jpg\")\n",
    "test_list = glob(\"/Users/woongjae/Desktop/gradu/project/dataset_v2/test/images/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train img : 5540\n",
      "valid img : 717\n",
      "test img : 720\n"
     ]
    }
   ],
   "source": [
    "print('train img :',len(train_list))\n",
    "print('valid img :',len(valid_list))\n",
    "print('test img :',len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/woongjae/Desktop/gradu/project/dataset_v2/train.text','w') as f:\n",
    "  f.write('\\n'.join(train_list) + '\\n')\n",
    "with open('/Users/woongjae/Desktop/gradu/project/dataset_v2/valid.text','w') as f:\n",
    "  f.write('\\n'.join(valid_list) + '\\n')\n",
    "with open('/Users/woongjae/Desktop/gradu/project/dataset_v2/test.text','w') as f:\n",
    "  f.write('\\n'.join(test_list) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': '../train/images', 'val': '../valid/images', 'test': '../test/images', 'nc': 22, 'names': ['Hoodie', 'Jacket', 'Mid-lenght dress', 'Pants', 'Shirt', 'coat', 'dress', 'fabric', 'jacket', 'jean', 'm2m', 'plain', 'shirt', 'short', 'shorts', 'skirt', 'slacks', 'suit', 'sweat', 'tie', 'tracksuit', 'tshirt'], 'roboflow': {'workspace': 'huseyin-ahrh5', 'project': 668, 'version': 5, 'license': 'CC BY 4.0', 'url': 'https://universe.roboflow.com/huseyin-ahrh5/01234/dataset/5'}}\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/woongjae/Desktop/gradu/project/dataset_v2/data.yaml','r') as f:\n",
    "  data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 'Users/woongjae/Desktop/gradu/project/dataset_v2/train.text', 'val': '../valid/images', 'test': '../test/images', 'nc': 22, 'names': ['Hoodie', 'Jacket', 'Mid-lenght dress', 'Pants', 'Shirt', 'coat', 'dress', 'fabric', 'jacket', 'jean', 'm2m', 'plain', 'shirt', 'short', 'shorts', 'skirt', 'slacks', 'suit', 'sweat', 'tie', 'tracksuit', 'tshirt'], 'roboflow': {'workspace': 'huseyin-ahrh5', 'project': 668, 'version': 5, 'license': 'CC BY 4.0', 'url': 'https://universe.roboflow.com/huseyin-ahrh5/01234/dataset/5'}, 'valid': 'Users/woongjae/Desktop/gradu/project/dataset_v2/valid.text'}\n"
     ]
    }
   ],
   "source": [
    "data['train'] = 'Users/woongjae/Desktop/gradu/project/dataset_v2/train.text'\n",
    "data['valid'] = 'Users/woongjae/Desktop/gradu/project/dataset_v2/valid.text'\n",
    "\n",
    "with open('/Users/woongjae/Desktop/gradu/project/dataset_v2/data.yaml','w') as f:\n",
    "  yaml.dump(data,f)\n",
    "  \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path, class_names):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2] == class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path, class_names, img_shape=(224, 224)):\n",
    "    label = tf.strings.split(file_path, os.path.sep)\n",
    "    label = label[-2] == class_names\n",
    "\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, img_shape)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, batch_size=32, cache=True, shuffle_buffer_size=1000):\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(label_path):\n",
    "    class_names = []\n",
    "    with open(label_path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            class_names.append(line)\n",
    "\n",
    "    return np.array(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch, class_names):\n",
    "    size = len(image_batch)\n",
    "    sub_size = int(size ** 0.5) + 1\n",
    "\n",
    "    plt.figure(figsize=(10, 10), dpi=80)\n",
    "    for n in range(size):\n",
    "        plt.subplot(sub_size, sub_size, n+1)\n",
    "        plt.subplots_adjust(left=0.125, bottom=0.1, right=0.9, top=0.9, wspace=0.2, hspace=0.5)\n",
    "        plt.title(class_names[label_batch[n]==True][0].title())\n",
    "        plt.imshow(image_batch[n])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, label_path, batch=32):\n",
    "    class_names = load_label(label_path)\n",
    "    data_dir = pathlib.Path(data_path)\n",
    "    list_ds = tf.data.Dataset.list_files(str(data_dir / '*/*'))\n",
    "\n",
    "\t# 데이터 확인\n",
    "    # for f in list_ds.take(5):\n",
    "    #     print(f.numpy())\n",
    "\n",
    "    labeled_ds = list_ds.map(lambda x: process_path(x, class_names))\n",
    "    train_ds = prepare_for_training(labeled_ds, batch_size=batch)\n",
    "\n",
    "    return train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m img, label \u001b[39min\u001b[39;00m train_dataset\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     show_batch(img, label, class_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for img, label in train_dataset.take(1):\n",
    "    show_batch(img, label, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
